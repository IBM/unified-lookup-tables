"""Evaluator for multiomics unicode experiments."""

__copyright__ = """
LICENSED INTERNAL CODE. PROPERTY OF IBM.
IBM Research Licensed Internal Code
(C) Copyright IBM Corp. 2024
ALL RIGHTS RESERVED
"""


import re
from typing import Any, Dict, List, Optional

import numpy as np
import numpy.typing as npt
import torch
from datasets import Dataset

from ..data.loaders.multiomics.tcga_augmented import SPECIAL_CLASS_TOKEN_TO_INT_REGEX
from .generic_evaluator import GenericEvaluator

CLASS_REGEX = re.compile("<LABEL>(<C\d+>)")


class MultiOmicsEvaluator(GenericEvaluator):
    """Multiomics unicode evaluator.
    Args:
        GenericEvaluator: generic evaluator class.
    """

    def apply_postprocessing(
        self, generated_model_test_output: List[str]
    ) -> Dict[str, List[Any]]:  # type: ignore
        """Applies postprocessing functions to predictions on multiomics and without unicode preprocessing.

        Args:
            generated_model_test_output: predictions from the model.
            groundtruth: groundtruth dataset.

        Returns:
            Processed multiomics class predictions for metric computations.
        """
        generated_model_test_output_product = self.get_prediction_string(
            generated_model_test_output
        )

        generated_model_test_output = {
            target: [
                (
                    int(SPECIAL_CLASS_TOKEN_TO_INT_REGEX.match(prediction).group(1))
                    if prediction is not None
                    else None
                )
                for prediction in list_prediction
            ]
            for (target, list_prediction) in generated_model_test_output_product.items()
        }

        return generated_model_test_output

    def get_prediction_string(
        self, generated_model_test_output: List[str]
    ) -> Dict[str, List[Any] | torch.Tensor]:
        """Get prediction string from prefixed pattern.

        Args:
            generated_model_test_output: predictions from the model.

        Returns:
            predictions from the models of the targets.
        """
        test_target_predictions: Dict[str, List[Optional[str]]] = {}

        for target in self.prediction_fields:
            extracted_predictions: List[Optional[str]] = []
            for output in generated_model_test_output:
                matched_output = CLASS_REGEX.search(output)
                if matched_output:
                    extracted_predictions.append(matched_output.group(1))
                else:
                    extracted_predictions.append(None)

            test_target_predictions[target] = extracted_predictions

        return test_target_predictions

    def compute(
        self,
        generated_model_test_output: List[str | torch.Tensor | npt.NDArray[np.float32]],
        groundtruth: Dataset,
    ) -> Dict[str, Dict[str, Any]]:
        """Computes metrics only.

        Args:
            generated_model_test_output: Predictions as generated by model.
            groundtruth: groundtruth values of the predictions.

        Returns:
            metrics computed.
        """

        predictions = self.apply_postprocessing(generated_model_test_output)
        indices_to_drop = set(
            [
                idx
                for _, prediction_list in predictions.items()
                for idx, prediction in enumerate(prediction_list)
                if prediction is None
            ]
        )
        indices_to_keep = list(set(range(len(groundtruth))) - indices_to_drop)
        # NOTE: filters predictions based on indices to drop
        return self._compute_metrics(
            predictions={
                target: [
                    prediction
                    for idx, prediction in enumerate(prediction_list)
                    if idx not in indices_to_drop
                ]
                for target, prediction_list in predictions.items()
            },
            groundtruth=groundtruth.select(indices=indices_to_keep),
        )
